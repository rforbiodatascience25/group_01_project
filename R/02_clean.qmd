---
title: "02_clean"
format:
  html:
    fig-format: png
---

# Cleaning data

## Loading libraries

```{r}
#| message: false
#| warning: false

library("stringr")
library("tidyverse")
```

Clean \_raw/ data to data/

Converts each of the following to a tibble dataframe in the tidy format

-   the expression GEODataTable from GDS in \_raw/

-   the metadata from GSE

    -   phenoData\$data - metadata concerning samples (patients)

    -   featureData\$data - metadata concerning genes

**Setup/Initialization**

```{r}
#| message: false
#| warning: false

data_dir <- "../data/"
raw_dir <- "../data/_raw/"
```

## GEODataTable from raw/raw_expression_data.rds

#### Loading in the data

Expression data of patients with different genes. (patient) Samples are stored as columns and gene names as rows, which we would like to flip, to align with tidy standards. But first we load the data from \_raw/

```{r}
exprs_geodf <- Table(read_rds(file.path(data_dir,"01_load_expression_data.rds")))
exprs_geodf <- as_tibble(exprs_geodf)
exprs_geodf
```

Now we can treat it as a normal dataframe to try to clean it to a tidy dataframe.

#### Removing empty rows

All 204 columns are (patient) Samples, and of type \<dbl\> with NA values. With this data we would like to keep the random NA values that appear throughout the dataset as they clearly represent no data. Substituting it with zeros would indicate that there is no expression of that gene in that sample, which is not necessarily the case (most likely not). Although, if an entire row is made of zeros, we would like to exclude that gene.

```{r}
fully_na <- exprs_geodf |>
  filter(if_all(starts_with("GSM"), is.na)) |> 
  select("ID_REF") 

dplyr::count(fully_na)
```

There are 3299 identifiers with completely empty rows in the expression dataset, given in the list "fully_na". We cannot use the gene column name: "IDENTIFIER", as it contains duplicates. Lets exclude fully_na indexes from the dataset:

```{r}
exprs_df <- exprs_geodf |> 
  anti_join(fully_na, by = "ID_REF")

exprs_df
```

With our little sanity check below, we can confirm that 3299 rows has been filtered from the data, matching the number of empty rows (fully_na)

```{r}
dim(exprs_geodf)[[1]] - dim(exprs_df)[[1]] - dim(fully_na)[[1]]
```

We could choose to reset ID_REF values and keep them as the index of the frame (essentially removing them), but that would obscure us from combining the expression dataframe with any potential meta data later on. We therefore instead denote the ID_REF column as lookup keys; since they're unique.

#### Transposing the dataframe

As according to tidy principles, we need variables (gene names) as columns and observations (samples) as rows, which is currently flipped. We therefore need to transpose the dataframe.

We can use pivot_longer to concatenate columns and values except *ID_REF*, and then pivot_wider to unpack the values along with *ID_REF*, leaving sample names as row names. Although, currently we have both *ID_REF* and *IDENTIFIER* functioning as column headers. We choose to exclude the IDENTIFIER column from the table, and combine it with future metadata tables. As long as the ID_REF is present, we can lookup any meta data there might be for either variables and observations.

```{r}
identifier_exprs <- exprs_df |>  # for later use
  select(ID_REF, IDENTIFIER)

exprs_df <- exprs_df |> 
  select(-IDENTIFIER) |> 
  
  #Packing column names to one (except ID_REF)
  pivot_longer(
    cols = -ID_REF,          
    names_to = "geo_accession", 
    values_to = "Value"  
  ) |>
  
  #Unpacking ID_REF as columns
  pivot_wider(
    names_from = ID_REF,
    values_from = Value
  )

exprs_df
```

Now we see the data transposed with 202 rows and 40,992 columns, as opposed to the opposite before.

## Removing low variance genes

To lighten the load on the server we also removed low variance genes, also if there is little to no variance the genes are probably not important.

```{r variance_distribution_across_genes}
gene_var <- exprs_df |> 
  # drop the sample ID column, keep only expression values
  select(-geo_accession) |> 
  summarise(across(everything(), ~ var(.x, na.rm = TRUE))) |> 
  pivot_longer(
    cols      = everything(),
    names_to  = "gene",
    values_to = "variance"
  )
```

```{r}
ggplot(gene_var, aes(x = variance)) +
  geom_histogram(bins = 100) +
  coord_cartesian(xlim = c(0, 0.5)) +
  theme_minimal()
ggsave("variance_distribution_across_genes.png", path = "../results", dpi = 300, width = 20, height = 12, units = "cm")
```

We decide the cutoff genes with a variance below 0.05, and have 2909 genes remaining

```{r}
genes_keep <- gene_var |> 
  filter(variance > 0.05) |> 
  pull(gene)

exprs_filtered <- exprs_df |> 
  select(geo_accession, all_of(genes_keep))

length(genes_keep)
```

## phenoData\$data from \_raw/gse11223.rds

Metadata concerning samples (patients), extracting the nested data frame phenodata, while removing

```{r}
gse11223 <- read_rds(file = file.path(data_dir,"01_load_meta_data.rds")) 

phenodata <- pData(phenoData(gse11223[1]))

phenodata |>
  summarise(across(everything(), ~ n_distinct(.x, na.rm = TRUE))) |>
  pivot_longer(
    everything(),
    names_to = "col",
    values_to = "n_levels"
  ) |>
  filter(n_levels <= 1)
```

Once we spotted the "one type columns" we drop them. Then we check the remaining ones.

```{r}
phenodata <- phenodata |>
  select(where(~ n_distinct(.x, na.rm = TRUE) > 1))

names(phenodata)
```

Then we remove the duplicate columns and rename them appropriately

```{r}
phenodata <- phenodata |>
  #Convert all columns with "characteristics_ch1" to long format
  pivot_longer(
    cols = starts_with("characteristics_ch1"),
    names_to = "old_col",
    values_to = "value"
  ) |>
  
  #Split
  separate(
    col  = value,
    into = c("prefix", "content"),
    sep  = ":",  # split at the first colon
    fill = "right",   # if content is missing, fill with NA
  ) |>
  
  #Clean the prefix
  mutate(
    prefix = str_replace_all(prefix, "\\s+", "_"),
    content = str_trim(content)
  ) |>
  
  select(-old_col) |>
  
  #Convert back to wide
  pivot_wider(
    names_from = prefix,
    values_from = content
  )

phenodata <- phenodata |>
  select(
    !ends_with(":ch1"),
    ends_with(":ch1")
  )

names(phenodata)
```

```{r}
phenodata <- phenodata[, !duplicated(as.list(phenodata))]

names(phenodata)
phenodata
```

The phenodata has been extracted from the gse11223 and now we will pick and choose the data that is, perhaps removing those variables that are of no importance for us, such as status, submission_date, type, channel_count, organism_ch1 (as they are all homo sapiens) and characteristics_ch1

## Selecting variables

Selecting which variables from phenodata that we would like to keep for further analysis.

```{r}
phenodata <- phenodata |> 
  select(geo_accession, patient, current_medication, birth_date, ethnicity, symptoms_onset_date, diagnosis_date, joint_problems, uc_flare_up, family_history, neutrophils, albumin, ibd_affected_relatives, smoking_status, smoking_start_date, smoking_stop_date, smoking_amount, other_illnesses, disease, anatomic_location, inflammation_status, procedure_date)
```

## Merging phenodata

Do a left_join() with phenodata and exprs_df on geo_accession

```{r}

finaldata <- right_join(phenodata, exprs_filtered, by = "geo_accession")
```

Stretching the data set so that genes

```{r}
finaldata <-  finaldata |> 
  pivot_longer(cols = 23:last_col(),
               names_to = "gene_id" ,
               values_to = "gene_expr" )

```

## featureData\$data from \_raw/gse11223.rds

Metadata concerning genes

```{r}
featuredata <- pData(featureData(gse11223))
```

Now we filter the same low variance genes from featuredata using the gene ID in genes_keep

```{r}
featuredata <- featuredata |>
  filter(ID %in% genes_keep)
```

## Exporting to data/

```{r}
write_csv(finaldata, file = "../data/02_dat_clean.csv.gz")
write_csv(featuredata, file = "../data/02_dat_genbank.csv.gz")
```

## Cleaning environment

```{r}
rm(list = ls())
```
